<!doctype html>
<html class="khawarislam_github_io">
  
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Khawar Islam - Applied Research Scientist</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body data-gr-c-s-loaded="true">
    <div class="wrapper">
        <table>
            <tbody>
                <tr>
                    <td width="160">
                        <img src="assets/img/khawarislam.jpeg" width="200">
                    </td>
                    <td>
                        <h1> Khawar Islam </h1>
                        <b>Senior Scientist - Autonomy AI, <a href="https://neubility.co/">Neubility</a>, Seoul, South Korea (June 2024 - Present)</b><br>
                        <span style="color:gray;">Previously: Applied Research Scientist, <a href="http://www.coremaxtech.com/">COREMAX AI Research</a>, Seoul, South Korea (until June 2024)</span><br>
                        Research Scientist - Generative AI, <a href="https://upendi.app/">UPENDI.AI</a><br>
                        Email: khawarr.islam [at] gmail.com<br>
                        <a href="assets/cv.pdf">CV</a> |
                        <a href="https://scholar.google.com.pk/citations?user=SFClxNEAAAAJ&hl=en">Google Scholar</a> |
                        <a href="https://dblp.org/pid/261/2710.html">dblp</a> |
                        <a href="https://github.com/khawar-islam">Github</a> |
                        <a href="https://www.linkedin.com/in/khawar-islam/">Linkedin</a>
                    </td>
                </tr>
            </tbody>
        </table>
        <table>
    <p>
        <h4>Currently, I am working as a Senior Scientist - Autonomy AI at Neubility, Seoul, South Korea, and as a Research Scientist - Generative AI at UPENDI.AI, Seoul, South Korea, where we are developing the next generation of personalized storyDiffusion, consistent character generation, image-2-image, and image-2-video translation. Previously, I was an Applied Research Scientist at COREMAX Technology, Seoul, South Korea, where my research focused on the generalization and robustness of neural networks, large language models for raw data, data augmentation, dataset construction, optical character recognition, and adversarial attacks.</h4>
    </p>
    <p>
        <h4>I received my M.S in Computer Science and Engineering from Sejong University, Seoul. During my master's studies, I worked on image understanding and image reconstruction approaches, including introducing an image compression method at CVPRw. Additionally, I have attended several summer schools and served as a technical volunteer at top AI and ML conferences.</h4>
    </p>
</table>



        <ul>
            <li><h2>International Conferences</h2></li>
            <table>
                <tbody>
                    <tr>
                        <td width="210">
                            <img src="assets/img/diffusemix.png" width="210">
                        </td>
                        <td>
                            <b>DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models</b><br>
                            <b>Khawar Islam</b>, Muhammad Zaigham Zaheer, Arif Mahmood, Karthik Nandakumar<br>
                            IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024<br>
                            [<a href="https://diffusemix.github.io/">Paper</a>] [<a href="https://diffusemix.github.io/">Supplementary</a>] [<a href="https://diffusemix.github.io/">Project Page</a>] [<a href="https://diffusemix.github.io/">Code</a>] [<a href="https://diffusemix.github.io/">Poster</a>] [<a href="https://diffusemix.github.io/">Dataset</a>] [<a href="https://diffusemix.github.io/">Video</a>]
                        </td>
                    </tr>
                    <tr>
                        <td width="210">
                            <img src="assets/img/fpvt.png" width="210">
                        </td>
                        <td>
                            <b>Face Pyramid Vision Transformer</b><br>
                            <b>Khawar Islam</b>, Muhammad Zaigham Zaheer, Arif Mahmood<br>
                            British Machine Vision Conference (<b>BMVC</b>), 2022<br>
                            [<a href="https://khawar-islam.github.io/fpvt/">Paper</a>] [<a href="https://bmvc2022.mpi-inf.mpg.de/0758_supp.pdf">Supplementary</a>] [<a href="https://khawar-islam.github.io/fpvt/">Project Page</a>] [<a href="https://github.com/khawar-islam/FPVT_BMVC22">Code</a>] [<a href="https://bmvc2022.mpi-inf.mpg.de/0758_poster.pdf">Poster</a>] [<a href="https://bmvc2022.mpi-inf.mpg.de/0758_video.mp4">Video</a>]
                        </td>
                    </tr>
                    <tr>
                        <td width="210">
                            <img src="assets/img/architecture.png" width="210">
                        </td>
                        <td>
                            <b>Image Compression with Recurrent Neural Network and Generalized Divisive Normalization</b><br>
                            <b>Khawar Islam</b>, Dang Lien Minh, Sujin Lee, Hyeonjoon Moon<br>
                            IEEE Conference on Computer Vision and Pattern Recognition Workshop (<b>CVPRw</b>), 2021<br>
                            [<a href="https://khawar-islam.github.io/cvpr/">Project Page</a>] [<a href="https://github.com/khawar-islam/ImageCompression">Code</a>] [<a href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/papers/Islam_Image_Compression_With_Recurrent_Neural_Network_and_Generalized_Divisive_Normalization_CVPRW_2021_paper.pdf">CVF Open Access</a>] [<a href="https://ieeexplore.ieee.org/document/9522707">IEEE Xplore</a>]
                        </td>
                    </tr>
                    <tr>
                        <td width="210">
                            <img src="assets/img/ivcnz.png" width="210">
                        </td>
                        <td>
                            <b>Face Recognition Using Shallow Age-Invariant Data</b><br>
                            <b>Khawar Islam</b>, Sujin Lee, Dongil Han, Hyeonjoon Moon<br>
                            Image and Vision Computing New Zealand (<b>IVCNZ</b>), 2021<br>
                            [<a href="https://ieeexplore.ieee.org/document/9653432">PDF</a>] [<a href="https://ieeexplore.ieee.org/document/9653432">IEEE Xplore</a>]
                        </td>
                    </tr>
                </tbody>
            </table>

            <li><h2>International Journals</h2></li>
            <table>
                <tbody>
                    <tr>
                        <td width="210">
                            <img src="assets/img/personsearch.png" width="210">
                        </td>
                        <td>
                            <b>Person search: New paradigm of person re-identification: A survey and outlook of recent works</b><br>
                            <b>Khawar Islam</b><br>
                            Journal of Image and Vision Computing (<b>IMAVIS</b>), 2020<br>
                            [<a href="https://www.sciencedirect.com/science/article/pii/S0262885620301025">Paper</a>]
                        </td>
                    </tr>
                </tbody>
            </table>

            <li><h2>Awards & Honors</h2></li>
            <ul>
                <li>NeurIPS Support, Sponsored by Naver Labs Europe, DeepMind, and Google AI, 2021</li>
                <li>Full Tuition Fee Waiver, School of Computer Engineering, Sejong University, 2020</li>
                <li>Prof. Stipend, CVPR Lab, Sejong University, 2020</li>
                <li>Conference Travel Grant, Ministry of Planning Commission, Pakistan, 2020</li>
                <li>Merit Scholarship for Bachelor Degree, Quaid-e-Azam Aligarh Society, Karachi, 2018</li>
                <li>Most Valuable Professional Award, C-SharpCorner, India, 2016 & 2017</li>
            </ul>

            <li><h2>Technical Skills</h2></li>
            <ul>
                <li><b>IP Algorithms:</b> Segmentation, Filter Design, Noise Removal, Compression, Super Resolution</li>
                <li><b>Object Detection:</b> SSD, YOLO-NAS, YOLOX, Faster R-CNN, DETR, GroundingDINO, YOLOv8</li>
                <li><b>DL Techniques:</b> Tracking, Optical Flow, Particle Filtering, Pose Estimation</li>
                <li><b>CV Algorithms:</b> Image Classification and Detection, Tracking, Siamese Networks</li>
                <li><b>Software Control:</b> JIRA, Agile, Scrum, GIT, Subversion</li>
                <li><b>Languages:</b> Python, Keras, JAVA, Unix Shell Scripting</li>
                <li><b>Deployment:</b> Docker, Kubernetes</li>
                <li><b>Editors:</b> Visual Studio Code, PyCharm, Jupyter Notebook</li>
                <li><b>Operating Systems:</b> WINDOWS 10, Ubuntu 18.04, Ubuntu 20.04, MAC OSX</li>
                <li><b>APIs:</b> PyTorch, TensorFlow, Caffe, OpenCV, Flask, Django</li>
            </ul>

            <li><h2>Recent Research/Industrial Projects</h2></li>
            <ul>
                <li>
                    <b>High-Quality Video Generation from Diffusion Models (Text-2-Video), 2024 - Present</b><br>
                    Designed identity-specific prompts and fine-tuned models for video generation.
                </li>
                <li>
                    <b>Image Restoration and Enhancement with GANs and Diffusion Models, 2024 - Present</b><br>
                    Worked on image super-resolution, deblurring, in-painting, and debazing.
                </li>
                <li>
                    <b>Image Editing Instructions with Diffusion Models (Image-to-Image), 2023</b><br>
                    Integrated Imagic, SINE, and LEDITS for high-resolution image editing.
                </li>
                <li>
                    <b>Foundation Multimodal Vision Language Models, 2023</b><br>
                    Generated captions and evaluated models on various metrics.
                </li>
                <li>
                    <b>Vision Language Models for Unseen Domains & Domain Shift, 2023</b><br>
                    Fine-tuned models to improve robustness and performed experiments on multiple datasets.
                </li>
                <li>
                    <b>Reliable Lightweight Real-Time Open-Vocabulary Object Detection, 2023</b><br>
                    Investigated and fine-tuned models for state-of-the-art performance.
                </li>
                <li>
                    <b>Online Continual Learning with Blurry Data and Incorrect Labels, 2022</b><br>
                    Developed a framework for diversity and purity in memory updates.
                </li>
                <li>
                    <b>Vision Transformer for General and Age-Invariant Face Recognition, 2021</b><br>
                    Proposed a new ViT architecture and conducted experiments on face aging datasets.
                </li>
            </ul>

            <li><h2>Academic Activities</h2></li>
            <ul>
                <li>Academic Services</li>
                <ul>
                    <li>Technical Volunteer - Advances in Neural Information Processing Systems (NeurIPS) 2021.</li>
                    <li>Technical Volunteer - International Joint Conferences on Artificial Intelligence (IJCAI) 2021.</li>
                    <li>Technical Volunteer - International Conference on Machine Learning (ICML) 2021.</li>
                    <li>Technical Volunteer - International Conference on Learning Representations (ICLR) 2021</li>
                    <li>Student Volunteer - IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021</li>
                    <li>Technical Volunteer - Association for the Advancement of Artificial Intelligence (AAAI) 2021</li>
                </ul>
                <li>Reviewer (International Journal)</li>
                <ul>
                    <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</li>
                    <li>International Journal of Computer Vision (IJCV).</li>
                    <li>Computer Vision and Image Understanding (CVIU).</li>
                </ul>
                <li>Reviewer (International Conference)</li>
                <ul>
                    <li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2019-2023.</li>
                    <li>IEEE International Conference on Computer Vision (ICCV) 2019-2023.</li>
                    <li>European Conference on Computer Vision (ECCV) 2020-2022.</li>
                    <li>Conference on Neural Information Processing Systems (NeurIPS) 2020-2022.</li>
                    <li>International Conference on Machine Learning (ICML) 2020-2023.</li>
                    <li>International Conference on Learning Representations (ICLR) 2021-2023.</li>
                    <li>Association for the Advancement of Artificial Intelligence (AAAI) 2020-2023.</li>
                    <li>IEEE Winter Conference on Applications of Computer Vision (WACV), 2020.</li>
                </ul>
                <li>Moderator</li>
                <ul>
                    <li>AI Deep Group on Facebook, 23.1K Members.</li>
                    <li>Artificial Intelligence, Machine and Deep learning Group, 754.4K members.</li>
                    <li>Deep Learning and Machine Learning, 109.5K Members.</li>
                    <li>Thailand Deep Learning, 19.8K Members.</li>
                    <li>Computer Vision, 129.6K Members.</li>
                    <li>Computer Vision and Machine Learning, 17.5K Members.</li>
                </ul>
            </ul>

            <li><h2>Summer and Winter Schools</h2></li>
            <ul>
                <li>OxML School, Oxford Machine Learning Summer School, 2022</li>
                <li>NYU AI School, New York Artificial Intelligence School, USA, 2022</li>
                <li>MLSS, Machine Learning Summer School, Taipei, Taiwan, 2021</li>
                <li>EEML, Eastern European Machine Learning Summer School, 2021</li>
            </ul>

            <li><h2>Q/A Mentorship Sessions</h2></li>
            <ul>
                <li>Yingzhen Li, Mentor at ICML, Imperial College London</li>
                <li>Evan Shelhamer, Mentor at ICML, DeepMind, Google</li>
                <li>Wei-Lun (Harry) Chao, Mentor at ICLR, Ohio State University</li>
                <li>Shakir Mohamed, Mentor at ICLR, DeepMind, Google</li>
                <li>Emmanuel Kahembwe, Mentor at ICLR, VDE (UK & Ireland)</li>
            </ul>
        </ul>
        <p>The design is taken from Prof. Sunghoon Im, DGIST.</p>

    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
